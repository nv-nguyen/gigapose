<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence.">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">GigaPose: Fast and Robust Novel Object Pose Estimation via One
              Correspondence</h1>
            <div class="is-size-4 publication-authors">
              <span class="author-block">
                <a href="https://nv-nguyen.github.io/">Van Nguyen Nguyen</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://imagine.enpc.fr/~groueixt/">Thibault Groueix</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://people.epfl.ch/mathieu.salzmann"> Mathieu Salzmann</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://vincentlepetit.github.io/">Vincent Lepetit</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>LIGM, Ecole des Ponts,</span>
              <span class="author-block"><sup>2</sup>Adobe,</span>
              <span class="author-block"><sup>3</sup>EPFL</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2311.14155" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=e-Yoo4Y59Lk&ab_channel=VanNguyenNguyen"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/nv-nguyen/gigapose"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-five-fifths">
          <h2 class="title is-3">Overview</h2>
          <div class="content has-text-justified">
            <image src="images/inference.png" width="1280" class="img-responsive" alt="overview"><br>
              <p class="text-justify">
                <strong>TL;DR:</strong> GigaPose is a "hybrid" template-patch correspondence approach to estimate 6D
                pose of novel objects in RGB images: GigaPose first uses templates, rendered images of the
                CAD models, to recover the out-of-plane rotation (2DoF) and then uses patch correspondences to estimate
                the remaining 4DoF. We experimentally show that GigaPose is (i) 38x faster for coarse pose stage, (ii)
                robust to segmentation errors made by the 2D detector, and (iii) more accurate with 3.2 AP improvement
                on seven core
                dataset of the BOP challenge.
              </p>
          </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-five-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We present GigaPose, a fast, robust, and accurate method for CAD-based novel object pose estimation in RGB
              images. GigaPose first leverages discriminative templates, rendered images of the CAD models, to recover
              the out-of-plane rotation and then uses patch correspondences to estimate the four remaining parameters.
              Our approach samples templates in only a two-degrees-of-freedom space instead of the usual three and
              matches the input image to the templates using fast nearest neighbor search in feature space, results in a
              speedup factor of 38x compared to the state of the art. Moreover, GigaPose is significantly more robust to
              segmentation errors. Our extensive evaluation on the seven core datasets of the BOP challenge demonstrates
              that it achieves
              state-of-the-art accuracy and can be seamlessly integrated with a refinement method.
            </p>
            <p>
              Additionally, we show the potential of GigaPose with 3D models predicted by recent work on 3D
              reconstruction from a single image, relaxing the need for CAD models and making 6D pose object estimation
              much more convenient.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <!-- Paper video. -->
  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-five-fifths">
          <h2 class="title is-3">Video</h2>
          <video class="video-border" width="1280" height="720" controls>
            <source src="../images/gigaPose.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>

        <!--/ Paper video. -->
      </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-five-fifths">
          <h2 class="title is-3">Qualitative results</h2>
          <div class="content has-text-justified">
            <image src="images/qualitative.png" width="1280" class="img-responsive" alt="qualitative"><br>
              <p class="text-justify">
                <strong>Qualitative results on LM-O and YCB-V datasets.</strong> The first column shows CNOS's
                segmentation. The second and third columns illustrate the outputs of the nearest neighbor search step,
                which includes the nearest template and the 2D-to-2D correspondences. The fourth column demonstrates the
                alignment achieved by applying the predicted affine transform to the template, then overlaying it on the
                query input. The last column show the final prediction after refinement.
              </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{nguyen2024gigaPose,
        author    = {Nguyen, Van Nguyen and Groueix, Thibault and Salzmann, Mathieu and Lepetit, Vincent},
        title     = {{GigaPose: Fast and Robust Novel Object Pose Estimation via One Correspondence}},
        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
        year      = {2024}
      }</code></pre>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">Further information</h2>
      If you like this project, check out our works on novel object segmentation / pose estimation:
      <ul>
        <li><a href="https://nv-nguyen.github.io/cnos/"> CNOS: A Strong Baseline for CAD-based Novel Object Segmentation
            (ICCV 2023 R6D) </a></li>
        <li><a href="https://nv-nguyen.github.io/template-pose/"> Templates for 3D Object Pose Estimation Revisited:
            Generalization to New Objects and Robustness to Occlusions (CVPR 2022)</a></li>
        <li><a href="https://github.com/nv-nguyen/pizza"> PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to
            6DoF Tracking (3DV 2022) </a></li>
      </ul>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is taken from <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>